{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yDVvFKobEPyA",
        "VXGWz0UpeCF5",
        "kY6q-XnAeKEe",
        "35gXwFWFKdbB"
      ],
      "authorship_tag": "ABX9TyN33diKh9hkhhW/Jno+uQnQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanwalker/MGSC496/blob/main/MGSC496_L11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the in-class notebook for MGSC496 Lecture 11.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RT9odU7BzKCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "if not os.path.exists('./models'):\n",
        "  os.mkdir('./models')\n"
      ],
      "metadata": {
        "id": "s7hNTaBJNEfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to mention:\n",
        "* Flattening images with `xb.view(xb.shape[0],-1)`\n",
        " * Esp in image convolution, we need to do this for flattening the data layers to do operations like softmax, or to get from the 2D image to a final class prediction\n",
        "* Discuss `model.train()` and `model.eval()`\n",
        "\n",
        "* Increasing loss / exploding gradients\n",
        " * Let's take a look at an example of this, below under **Misc:Increasing Loss / Exploding Gradients**\n",
        " * [A good explanation of why too-large learning rates can lead to gradient explosion](https://stats.stackexchange.com/questions/315664/gradient-descent-explodes-if-learning-rate-is-too-large)\n",
        "* Cross Entropy Loss\n",
        " * Cross Entropy Loss is a good loss function to use for classification problems (esp w/ multiple classes).\n",
        " * It compares two distributions (and is often used to compare a one-hot encoded class label to a softmax predicted prob of a data point belonging to each class)\n",
        " * Note that the Cross Entropy Loss is asymmetric, so make sure that you are putting the labels as the second argument!\n",
        " * [Comparing Cross Entropy Loss to MSE](https://dhruvmetha.medium.com/why-cross-entropy-loss-6f221202c8b8#:~:text=Comparison%20with%20Mean%20Squared%20Error%20(L2%20loss))\n",
        "* Two more advanced topics that we didn't cover are:\n",
        " * Text/sequence embeddings -- getting a numerical vector out of text ( a sequence of words) or even sequences of other data. You may have heard of Word2Vec which is a popular example of this.\n",
        "  * Often this is done by masking (hiding) some of the elemnents in the sequnce (e.g., a word) and creating an NN that predicts the hidden elements. In doing so, we can make some middle layer of the NN have neurons represent the input sequence as a set of numerical values. These become the \"vector\" that represents the text. \n",
        " * Recurrent Neural Networks: Feed the output of the NN back into it as an input.\n",
        "  * Has lots of new types of problems to deal with like vanishing/exploding gradients as backward prop has to go through the net multiple times.\n",
        "  * Can sacrific long term memory of what is happening. There are some approaches to dealing with this (like letting some inputs skip over the pass through the NN). You may have heard of LSTMs - Long Term Short Term memory NNs which are examples of RNNs\n",
        " * Transformers - An entirely different approach to handling input sequence data compared to RNNs. This is much more similar to the sequence embeddings approaches discussed, but has numbers capture how much attention is paid to different parts of the sequence when trying to predict a masked part of it."
      ],
      "metadata": {
        "id": "7Yt8xDXSyHVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Exercise Solution: Make Your Own Neural Network Class"
      ],
      "metadata": {
        "id": "QsF08aYbBbOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>\n",
        "<img src=\"https://drive.google.com/uc?id=1sk8CSP26YY7sfyzmHGFXncuNRujkvu9v\" align=\"left\">\n",
        "\n",
        "<font size=3 color=\"darkred\">Exercise:Make your own Neural Network Class</font>\n",
        "\n",
        "\n",
        "Make your own neural network class by following the examples above. Remember your class should have a constructor that defines and stores the layers; and a forward method that passes the input through each layer in the right order. Feel free to use `torch.nn.Sequential` if you wish.\n",
        "\n",
        "\n",
        "Your neural net class should be called `MyNet` and have the following architecture:\n",
        "* A fully connected (linear) layer that takes input of 7 dimensions and outputs 32 dimensions\n",
        "* A sigmoid layer (you can use `torch.nn.Sigmoid`)\n",
        "* Another fully connected (linear) layer with an input that matches the output of the last layer and an output of 64 dimensions\n",
        "* Another sigmoid layer\n",
        "* A third fully connected (linear) layer with an input that matches the output of the last layer and an output of 5 dimensions\n",
        "* A softmax layer\n",
        "\n",
        "When you have defined your class, make an instance of an object of that class and pass a random torch tensor of shape (3,7). Also try passing a random torch tensor of shape (10,7).\n",
        "\n",
        "Unlike in the examples above, however, I want you to print out `x.shape` in between each layer that you pass it through in the `.forward` method. This will allow us to \"see\" how the tensor changes shape as it goes through each layer."
      ],
      "metadata": {
        "id": "pA_8mSdz9b65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your NN class\n",
        "class MyNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = torch.nn.Linear(7,32) \n",
        "    self.sig1 = torch.nn.Sigmoid()  \n",
        "    self.fc2 = torch.nn.Linear(32,64)\n",
        "    self.sig2 = torch.nn.Sigmoid()\n",
        "    self.fc3 = torch.nn.Linear(64,5)\n",
        "    self.softmax = torch.nn.Softmax(dim=0) \n",
        "  \n",
        "  def forward(self,x):\n",
        "    print(x.shape)\n",
        "    x = self.fc1(x)\n",
        "    print(x.shape)\n",
        "    x = self.sig1(x)\n",
        "    print(x.shape)\n",
        "    x = self.fc2(x)\n",
        "    print(x.shape)\n",
        "    x = self.sig2(x)\n",
        "    print(x.shape)\n",
        "    x = self.fc3(x)\n",
        "    print(x.shape)\n",
        "    x = self.softmax(x)\n",
        "    print(x.shape)\n",
        "    return x"
      ],
      "metadata": {
        "id": "IEX3gat49b66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make an instance of an object of your NN Class\n",
        "model = MyNet()"
      ],
      "metadata": {
        "id": "WaXluWt0AK-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a random tensor of shape (3,7) through your model\n",
        "model.forward(torch.rand(3,7))"
      ],
      "metadata": {
        "id": "1Lh_mo9jAOyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a random tensor of shape (10,7) through your model\n",
        "model.forward(torch.rand(10,7))"
      ],
      "metadata": {
        "id": "Cl4pf1-NAb4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: Why did the model allow us to pass different tensors of shape `(n,7)` into it (for `n`=3, 10)? Could we have passed a tensor of shape `(n,7)` for arbitrary `n`? \n",
        "\n",
        "A: Pytorch is built to assume that the first dimension of tensors that you pass into models will always be the \"batch\" dimension, as the designers understood that we would like to take advantage of vectorized computation to run large batches of data through our model at once. So, yes, it would have accepted a tensor of shape `(n,7)` for arbitrary `n` as input.\n",
        "\n",
        "Looking at how the shape of `x` changes as it passes through the layers, do you understand what is going on?"
      ],
      "metadata": {
        "id": "KviJ-9gw9b67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "BqvC77nY9b67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Exercise Solution: Calculate the Output Dimension of a pooling layer"
      ],
      "metadata": {
        "id": "QnI-ITmkQHa4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$O_d = \\frac{I_d + 2*P_d - R_d}{S_d} + 1$\n",
        "\n",
        "where:\n",
        "- $I_d$ is the size of the input layer in the $d^{th}$ dimension\n",
        "- $P_d$ is the padding size in the $d^{th}$ dimension\n",
        "- $R_d$ is the receptive field size in the $d^{th}$ dimension\n",
        "- $S_d$ is the stride in the $d^{th}$ dimension"
      ],
      "metadata": {
        "id": "ye3ZOwEaQjO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>\n",
        "<img src=\"https://drive.google.com/uc?id=1sk8CSP26YY7sfyzmHGFXncuNRujkvu9v\" align=\"left\">\n",
        "\n",
        "<font size=3 color=\"darkred\">Exercise: Calculate the Output Dimension of a pooling layer</font>\n",
        "\n",
        "Write a python function that takes arguments `input_size_d`, `padding_size_d`, `receptive_field_size_d`, and `stride_size_d` and returns `output_size_d` using the formula above.\n",
        "\n",
        "Suppose you have a tensor of shape `(9,9)` and you run it through a pooling layer with a padding of (1,1), a receptive field of (2,3) and a stride of (1,1). Use your function to calculate the output size in each dimension (i.e., call your function twice, once for each dimension).\n",
        "\n"
      ],
      "metadata": {
        "id": "4JLvJAb3Sgi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it out\n",
        "def get_pooling_output_d(input_size_d, padding_size_d, receptive_field_size_d, stride_size_d):\n",
        "  output_size_d = (input_size_d + 2*padding_size_d - receptive_field_size_d)/stride_size_d + 1\n",
        "  return output_size_d\n",
        "  "
      ],
      "metadata": {
        "id": "lS2kCouoQAx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it out\n",
        "get_pooling_output_d(9,1,2,1)"
      ],
      "metadata": {
        "id": "MJZTjhZ0SgjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pooling_output_d(9,1,3,1)"
      ],
      "metadata": {
        "id": "z0eoHBIMSkc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "oX0WaqJ0SgjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Exercise Solution: Make a Convolution Layer and apply it to a random tensor"
      ],
      "metadata": {
        "id": "t6j1wJhOZPq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>\n",
        "<img src=\"https://drive.google.com/uc?id=1sk8CSP26YY7sfyzmHGFXncuNRujkvu9v\" align=\"left\">\n",
        "\n",
        "<font size=3 color=\"darkred\">Exercise: Use a PyTorch Convolution layer to explore different filters </font>\n",
        "\n",
        "PyTorch convolution layers have filter weights that are learned, just as any weights in NNs are trained. However, we can set the weights of these layers manually to see how 2D convolutions with different filters affect image inputs. Let's do that and explore some different filters applied to (just one color channel of) CIFAR images.\n",
        "\n",
        "<br />\n",
        "\n",
        "Do the following:\n",
        "1. Run the code below for a slightly modified version of the imshow function that will allow us to plot multiple images side by side.\n",
        "\n",
        "2. Run the code to grab an example image and label from the CIFAR data.\n",
        "\n",
        "3. Let's create the filters (kernels) that are shown in the animated image above labelled \"Convolution for Edge Detection\". Each of these is a 3x3 filter. We can define it by calling `torch.tensor()` on a multidimensional array or list. Note that we will want to create a tensor of shape `(1,1,3,3)` where the 1st dimension is the batch dimension, the 2nd dimension is the \"channel\" of the image, and the next two dimensions are the x,y pixels of the image. So, you can define these filters by calling `torch.tensor()` on a list of lists and then calling `.view(1,1,3,3)` to change it to the shape we want. Call these filter tensors `filter1`, `filter2`, etc. Start by setting the variable `filter=filter1` (later we will change this to look at all the filters we made).\n",
        "\n",
        "4. Create a 2d convolution layer called `c` with 1 in channel, 1 out channel, padding and stride of 1, and a kernel size of 3x3.\n",
        "\n",
        "5. We can set the weights of a conv2d layer manually, using `c.weight = ...` but we have to do this within a `with torch.no_grad():` block. Set the weight of your convolution layer to `filter1`.\n",
        "\n",
        "6. Grab the first color channel of the CIFAR image `exImage[0]`. We want to make this a tensor of shape `(1,1,32,32)`. Use `.view()` to accomplish this and call the resulting tensor `input`\n",
        "\n",
        "7. Run `input` through the convolutional layer `c` to get the `output`. Look at the shape of `output`.\n",
        "\n",
        "8. Now we will plot the input image, the filter, and the output image side by side using our `imshow` function. `imshow` will take a list of tensors to display, but wants each one to be of shape `(1,X,Y)`. So, we can plot a `(1,32,32)` shaped tensor (like our input and output)  or even a `(1,3,3)` shaped tensor like `filter`. Use `.view()` to change the input, output and filter tensors to these shapes, make a list of them and pass it to `imshow`\n",
        "\n",
        "Finally, re-run the above but set `filter=filter2`, `filter=filter3`, etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "9KJZJS1_TrCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Run the code below to define a modified imshow function that plots images side by side\n",
        "#  You can now pass this function a list of images represented as tensors, and it will plot each side by side\n",
        "def imshow(img,transform=True, titles = None):\n",
        "  if not(isinstance(img,list)):\n",
        "    img = [img]\n",
        "  fig, ax = plt.subplots(1,len(img),figsize=(15,15))\n",
        "  for i,img in enumerate(img):\n",
        "    if img.shape[0]==3:\n",
        "      img = img.permute(1,2,0)\n",
        "    elif img.shape[0]==1: \n",
        "      img = img[0]\n",
        "    if transform:\n",
        "      img = img/2 + 0.5\n",
        "    if isinstance(ax,np.ndarray):   \n",
        "      ax[i].imshow(img.cpu().numpy())\n",
        "      if titles is not None:\n",
        "        ax[i].set_title(titles[i])\n",
        "    else:\n",
        "      ax.imshow(img.cpu().numpy())\n",
        "      fig.set_figheight(5)\n",
        "      fig.set_figwidth(5)\n"
      ],
      "metadata": {
        "id": "kEiZbi3_a-cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR dataset\n",
        "transform_cifar = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]) \n",
        "\n",
        "trainset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
        "                                        download=True, transform=transform_cifar)\n"
      ],
      "metadata": {
        "id": "DfYYr3QbgwF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Grab an example image and its label from the CIFAR dataset\n",
        "exImage, exLabel = trainset_cifar[ np.random.randint(0,trainset_cifar.data.shape[0]) ]\n",
        "imshow(exImage)\n",
        "print(trainset_cifar.classes[exLabel])"
      ],
      "metadata": {
        "id": "q1kA7xBGhhUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. through 8. \n",
        "filter1 = torch.tensor([[[[1.,2.,1.],[0.,0.,0.],[-1.,-2.,-1.]]]])\n",
        "filter2 = torch.tensor([[[[0.,-1.,0.],[-1.,5.,-1.],[0.,-1.,0.]]]])\n",
        "filter3 = torch.tensor([[[[0.,1.,2.],[-1.,0.,1.],[-2.,-1.,0.]]]])\n",
        "filter4 = torch.tensor([[[[1.,0.,-1.],[0.,0.,0.],[-1.,0.,1.]]]])\n",
        "filter = filter3\n",
        "\n",
        "print(trainset_cifar.classes[exLabel])\n",
        "c = torch.nn.Conv2d(in_channels=1, out_channels=1, stride=1, padding=1, kernel_size=(3,3))\n",
        "with torch.no_grad():\n",
        "  c.weight = torch.nn.Parameter(filter)\n",
        "input = exImage[0]\n",
        "output = c(input.view(1,1,32,32))\n",
        "imshow([input,filter.view(1,3,3),output.view(1,32,32).detach()], titles=['input','filter','output'])"
      ],
      "metadata": {
        "id": "dq2Gx3pdTrCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "Wc5Knbv1TrCV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtrsfEMUYGcG"
      },
      "source": [
        "# In-Class Exercise: Train a CNN for labeling CIFAR-10 images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPiDX_aSYGcR"
      },
      "source": [
        "While simple neural networks perform well for the MNIST data, they work badly for the CIFAR-10 images due to the complexity of these images that have three color channels. By using advanced architecture such as convolution layers, we will build a better model than the current one. \n",
        "\n",
        "Before writing a code block for an advanced model, let's think about its structure. First, we need to capture edges or other features in images. Convolution layers are what we need for this purpose. The number of output channels would be larger than the number of input channels to let the model learn many features as the following line.\n",
        "\n",
        "```python\n",
        "torch.nn.Conv2d(in_channels=3, out_channels=sizeOutChannels, kernel_size=3, padding=1)\n",
        "```\n",
        "\n",
        "Next, by adding a batch normalization layer, we can increase speed and performance of training. Note that `num_features` in the `BatchNorm2d` should match the `out_channels` in the previous convolution layer.\n",
        "\n",
        "```python\n",
        "torch.nn.BatchNorm2d(num_features = sizeOutChannels)\n",
        "```\n",
        "\n",
        "Any activation layer can be added after the batch normalization layer. In this lecture, we will use the ReLU function. \n",
        "\n",
        "```python\n",
        "torch.nn.ReLU()\n",
        "```\n",
        "\n",
        "Lastly, add a pooling layer to aggregate values. \n",
        "\n",
        "```python\n",
        "torch.nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "```\n",
        "\n",
        "Our model is built on the combinations of convolution layers, batch normalization layers, activation layers, and pooling layers. \n",
        "\n",
        "Below, create a new model class called CnnCIFAR (it needs to inherit from `torch.nn.Module`).\n",
        "\n",
        "You can model it after the NN that we built above. However, to make your `forward` method simpler and to better organize your layers, you should  combine layers into logical blocks using `torch.nn.Sequential()`.\n",
        "\n",
        "In your constructor:\n",
        "- Don't forget to call the super's constructor first\n",
        "- add arguments `sizeOutChannels`(the out_channels of the Conv2D layer), `sizeHiddenLayer` (the out features of the fully connected linear layer) to your constructor.\n",
        "- define a convolution layer block that consists of sequential layers of:\n",
        " - a Conv2d\n",
        " - a BatchNorm2d\n",
        " - a ReLU\n",
        " - a MaxPool2d (`kernel_size=2`, `size=2`)\n",
        "- define a fully connected layer block that consists of sequential layers of:\n",
        " - a linear layer with the appropriate input feature size to match the output of the convolution layer (it will be some number *`sizeOutChannels` -- you'll have to figure out what that number is based on the `kernel_size` and `stride` of the MaxPool2d layer) and the output size given by our argument `sizeHiddenLayer`\n",
        " - a ReLU\n",
        " - a Dropout (`p=0.2`)\n",
        " - another linear layer with output size of 10 (for each of the 10 classes a CIFAR image can belong to).\n",
        "\n",
        "Define your `forward` method to pass the input x through the logical layer blocks that are defined in your constructor.\n",
        "- IMPORTANT: you'll want to flatten the output of the convolution layer block before passing it into the fully connected layer block. You can do this with `x.view(x.size(0),-1)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKE4HWYiVr-Q"
      },
      "source": [
        "# Write you CnnCifar class here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HsUDKFJa_4S"
      },
      "source": [
        "Run the below code (to ensure that CIFAR10 is loaded and transformed properly, in case a session disconnect happened earlier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGqnWAc7eBIG"
      },
      "source": [
        "# Load the CIFAR10 data\n",
        "transform_cifar = transforms.Compose( [ transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) ] )\n",
        "trainset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform_cifar)\n",
        "testset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "batch_size = 64\n",
        "train_dl_cifar = DataLoader(trainset_cifar, batch_size=batch_size, shuffle=True)\n",
        "test_dl_cifar = DataLoader(testset_cifar, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QleVIE1rbhvt"
      },
      "source": [
        "Run the below code to define the model with the given arguments for `sizeOutChannels`, `sizeHiddenLayer` and to define a loss function (here we'll use the cross entropy loss) and optimizer (here we'll use Stochastic Gradient Descent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoBup_-qfwME"
      },
      "source": [
        "cnnCIFAR = CnnCIFAR(sizeOutChannels = 16, sizeHiddenLayer = 50)\n",
        "cnnCIFAR = cnnCIFAR.cuda() # define the model for cuda\n",
        "\n",
        "cnn_CIFAR_loss_fn = torch.nn.CrossEntropyLoss() # use cross entropy loss\n",
        "cnn_CIFAR_opt = torch.optim.SGD(cnnCIFAR.parameters(), lr=0.003, momentum=0.9) # where did I get these \"magic numbers?\"  Trial and error and voodoo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PukJ4aaIqTxZ"
      },
      "source": [
        "cnnCIFAR.train()\n",
        "# We will train the model for 15 epochs as same as the previous fully connected network.\n",
        "for epoch in range(15):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_dl_cifar:\n",
        "        # data to train\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # intitiate gradients\n",
        "        cnn_CIFAR_opt.zero_grad()\n",
        "\n",
        "        # calculate loss and update parameters\n",
        "        outputs = cnnCIFAR(inputs)\n",
        "        loss = cnn_CIFAR_loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        cnn_CIFAR_opt.step()\n",
        "\n",
        "        # Sum losses\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} loss = {running_loss/len(train_dl_cifar)}\") # print out the loss (averaged over all the predictions in the batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYlwo7XP0aBm"
      },
      "source": [
        "Let's evaluate the trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP42jRmKieoA"
      },
      "source": [
        "cnnCIFAR.eval() # put the model into evaluation mode -- may affect some types of layers (e.g., dropout)\n",
        "with torch.no_grad():\n",
        "  running_loss = 0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  numClasses = len(test_dl_cifar.dataset.classes)\n",
        "  cm = np.zeros((numClasses,numClasses),dtype=np.int32) # an empty matrix to hold the confusion matrix, we'll sum the confusion matrices for each batch\n",
        "  for xb, yb in test_dl_cifar:\n",
        "    xb = xb.cuda()\n",
        "    yb = yb.cuda()\n",
        "    pred = cnnCIFAR(xb)\n",
        "    predLabels = torch.argmax(pred,dim=1)\n",
        "    cm += confusion_matrix(yb.cpu().numpy(),predLabels.cpu().numpy(),range(0,10)) # add this batch's confusion matrix to the total matrix -- we have to specify the list of class indexes, or sklearn will shorten our cm to only the classes seen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb1YNseJrkg3"
      },
      "source": [
        "acc = np.diag(cm)/cm.sum(axis=1)\n",
        "print(cm, '\\n', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqZwMDmJ1Bmq"
      },
      "source": [
        "The convolution neural network performs better than the previous fully connected network. Could we still do better? We only added one convolutional layer block. But these images belong to many different classes.  You should now go back and try to experiment with the model. What if you run it for more epochs? What if you try changing the arguments for our model (e.g., try adjusting the parameters `sizeOutChannels`, `sizeHiddenLayer`). You could also try adding another convolutional layer block.  Remember the final output needs to match the number of classes we're trying to predict.  See if you can do better. Don't be afraid to google around for examples of CNN's applied to images. What do they do? What kind of performance can they achive on CIFAR (this is a well known and standard dataset).  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution: Don't look until you've tried it"
      ],
      "metadata": {
        "id": "yDVvFKobEPyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "if not os.path.exists('./models'):\n",
        "  os.mkdir('./models')\n",
        "\n",
        "# Load the CIFAR10 data\n",
        "transform_cifar = transforms.Compose( [ transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) ] )\n",
        "trainset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform_cifar)\n",
        "testset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "batch_size = 64\n",
        "train_dl_cifar = DataLoader(trainset_cifar, batch_size=batch_size, shuffle=True)\n",
        "test_dl_cifar = DataLoader(testset_cifar, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define you CnnCifar Class\n",
        "class CnnCIFAR(torch.nn.Module):\n",
        "  def __init__(self, sizeOutChannels, sizeHiddenLayer):\n",
        "    super(CnnCIFAR, self).__init__()\n",
        "    self.conv_layer = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=3, out_channels=sizeOutChannels, kernel_size=3, padding=1),\n",
        "        torch.nn.BatchNorm2d(num_features = sizeOutChannels),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc_layer = torch.nn.Sequential(\n",
        "        torch.nn.Linear(sizeOutChannels*16*16, sizeHiddenLayer),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(p=0.2),\n",
        "        torch.nn.Linear(sizeHiddenLayer, 10) # return values to predict a class among 10 labels.\n",
        "    )  \n",
        "\n",
        "  def forward(self, x):\n",
        "    # conv_layer\n",
        "    x = self.conv_layer(x)\n",
        "    # flatten\n",
        "    x = x.view(x.size(0), -1)\n",
        "    # fc_layer\n",
        "    x = self.fc_layer(x)\n",
        "    return x \n",
        "\n",
        "\n",
        "# Define the model and loss and optimizer\n",
        "cnnCIFAR = CnnCIFAR(sizeOutChannels = 16, sizeHiddenLayer = 50)\n",
        "cnnCIFAR = cnnCIFAR.cuda() # define the model for cuda\n",
        "\n",
        "cnn_CIFAR_loss_fn = torch.nn.CrossEntropyLoss() # use cross entropy loss\n",
        "cnn_CIFAR_opt = torch.optim.SGD(cnnCIFAR.parameters(), lr=0.003, momentum=0.9) # where did I get these \"magic numbers?\"  Trial and error and voodoo.\n",
        "\n",
        "# Train the model\n",
        "cnnCIFAR.train()\n",
        "# We will train the model for 15 epochs as same as the previous fully connected network.\n",
        "for epoch in range(15):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_dl_cifar:\n",
        "        # data to train\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # intitiate gradients\n",
        "        cnn_CIFAR_opt.zero_grad()\n",
        "\n",
        "        # calculate loss and update parameters\n",
        "        outputs = cnnCIFAR(inputs)\n",
        "        loss = cnn_CIFAR_loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        cnn_CIFAR_opt.step()\n",
        "\n",
        "        # Sum losses\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} loss = {running_loss/len(train_dl_cifar)}\") # print out the loss (averaged over all the predictions in the batch)\n",
        "\n",
        "\n",
        "# Evaluate the trained model\n",
        "cnnCIFAR.eval() # put the model into evaluation mode -- may affect some types of layers (e.g., dropout)\n",
        "with torch.no_grad():\n",
        "  running_loss = 0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  numClasses = len(test_dl_cifar.dataset.classes)\n",
        "  cm = np.zeros((numClasses,numClasses),dtype=np.int32) # an empty matrix to hold the confusion matrix, we'll sum the confusion matrices for each batch\n",
        "  for xb, yb in test_dl_cifar:\n",
        "    xb = xb.cuda()\n",
        "    yb = yb.cuda()\n",
        "    pred = cnnCIFAR(xb)\n",
        "    predLabels = torch.argmax(pred,dim=1)\n",
        "    cm += confusion_matrix(yb.cpu().numpy(),predLabels.cpu().numpy(),labels=range(0,10)) # add this batch's confusion matrix to the total matrix -- we have to specify the list of class indexes, or sklearn will shorten our cm to only the classes seen\n",
        "\n",
        "acc = np.diag(cm)/cm.sum(axis=1)\n",
        "print(cm, '\\n', acc)\n"
      ],
      "metadata": {
        "id": "Y_YXhoAVETxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "cCkLcbvRHuUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc: Load MNIST and Train a simple NN model on it "
      ],
      "metadata": {
        "id": "VXGWz0UpeCF5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpak2tSMR9Pd"
      },
      "source": [
        "# 1. Import Stuff\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# 2. Our imshow() function from earlier\n",
        "def imshow(img):\n",
        "  if img.shape[0]==3: # its probably (color,width,height) so make it (width,height,color) which is what plt.imshow() wants\n",
        "    img = img.permute(1,2,0)\n",
        "  elif img.shape[0]==1: # its probably a (1,width,height) so make it just (width,height) which is what plt.imshow() wants for a single channel\n",
        "    img = img[0]\n",
        "  img = img/2 + 0.5 # undo our normalization, just to show the image, because plt's imshow() expects numbers to be between (0,1)\n",
        "  plt.imshow(img.cpu().numpy()) # plt's imshow() knows how to work with numpy arrays, not tensors, so we'll convert it first\n",
        "\n",
        "# 3. A function to save our NN to a file\n",
        "def nnSave(model,opt,path):\n",
        "  torch.save({'model_class': model.__class__, # this is a pointer to the definition of the model's class\n",
        "              'model_args': model.init_args, # init_args is the only property we have to add to a NN class ourselves for this function to work.\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'opt_class': opt.__class__,\n",
        "              'opt_args': opt.defaults,\n",
        "              'opt_state_dict':opt.state_dict()},\n",
        "            path)\n",
        "\n",
        "# 4. A function to load our NN from a file  \n",
        "def nnLoad(path):\n",
        "  cp = torch.load(path)\n",
        "  model = cp['model_class'](**cp['model_args']) # equivalent to model = ModelClass(arg1,arg2,...)\n",
        "  model.load_state_dict(cp['model_state_dict'])\n",
        "  opt = cp['opt_class'](model.parameters(),**cp['opt_args']) # equivalent to opt = OptClass(arg1,arg2,...)\n",
        "  opt.load_state_dict(cp['opt_state_dict'])\n",
        "  return model, opt\n",
        "\n",
        "\n",
        "# 5. Definition of a Neural Network called ImgNet -- (input layer, FC hidden layer 1, ReLU, FC hidden layer 2, ReLU, FC hidden layer 3, ReLU, logSoftMax)\n",
        "class ImgNet(torch.nn.Module):\n",
        "  def __init__(self,sizeInput,sizeHiddenLayer1,sizeHiddenLayer2,sizeOutput):\n",
        "    self.init_args = {k:v for k,v in locals().items() if k!='self' and k!='__class__'} # this funny line captures the name and values of the args so we can save them w/ nnSave()\n",
        "    super().__init__()\n",
        "    self.fc1 = torch.nn.Linear(sizeInput,sizeHiddenLayer1)\n",
        "    self.relu1 = torch.nn.ReLU()\n",
        "    self.fc2 = torch.nn.Linear(sizeHiddenLayer1,sizeHiddenLayer2)\n",
        "    self.relu2 = torch.nn.ReLU()\n",
        "    self.fc3 = torch.nn.Linear(sizeHiddenLayer2,sizeOutput)\n",
        "    self.logsoftmax = torch.nn.LogSoftmax(dim=1) # We are using dim=1 here because the 0th dimension will be the batch dimension\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.logsoftmax(x)\n",
        "    return x\n",
        "\n",
        "# 6. Fit function for training a NN\n",
        "def fit(num_epochs, model, train_dl, loss_fn, opt):\n",
        "  model.train() # make sure the model is in training mode (instead of eval mode)\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss=0\n",
        "    for xb,yb in train_dl: \n",
        "      xb = xb.view(xb.shape[0],-1) # This will keep the first dimension as the batch dimension and flatten all the others\n",
        "      xb = xb.to(\"cuda\",non_blocking = True) # this puts the tensor in the GPU's memory. non_blocking=True ensures that RAM->GPU RAM copy doesn't block other operations\n",
        "      yb = yb.to(\"cuda\", non_blocking = True)\n",
        "      opt.zero_grad() # We'll start by zero'ing the gradient. We could have done this at the end of this loop, but this ensures we have no errant gradients lying around for the first iteration of the loop\n",
        "      pred = model(xb) # run the input through the model and get the predictions \n",
        "      loss = loss_fn(pred, yb) # calculate the loss -- we'd have to check that the loss_fn gets the prediction and true values in the form it expects -- so its wise to check the docs of whatever loss_fn we use\n",
        "      loss.backward() # propagate the loss backward\n",
        "      opt.step() # tell the optimizer to do its thing\n",
        "      running_loss+=loss.item() # add up the running loss (remember the output of loss will be a scalar, so loss.item() will just be a numerical value)\n",
        "    print(f\"Epoch {epoch} loss = {running_loss/len(train_dl)}\") # print out the loss (averaged over all the predictions in the batch)\n",
        "\n",
        "# 7. Test function for evaluating a NN\n",
        "def test(model, test_dl, loss_fn):\n",
        "  model.eval() # put the model into evaluation mode -- may affect some types of layers (e.g., dropout)\n",
        "  with torch.no_grad():\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    numClasses = len(test_dl.dataset.classes)\n",
        "    cm = np.zeros((numClasses,numClasses),dtype=np.int32) # an empty matrix to hold the confusion matrix, we'll sum the confusion matrices for each batch\n",
        "    #print(cm.shape)\n",
        "    for xb, yb in test_dl:\n",
        "      xb = xb.view(xb.shape[0],-1)\n",
        "      xb = xb.to(\"cuda\")\n",
        "      yb = yb.to(\"cuda\")\n",
        "      pred = model(xb)\n",
        "      predLabels = torch.argmax(pred,dim=1)\n",
        "      cm += confusion_matrix(yb.cpu().numpy(),predLabels.cpu().numpy(),labels=range(0,10)) # add this batch's confusion matrix to the total matrix -- we have to specify the list of class indexes, or sklearn will shorten our cm to only the classes seen\n",
        "      loss = loss_fn(pred,yb)\n",
        "      running_loss+=loss.item()\n",
        "    ave_loss = running_loss/len(test_dl)\n",
        "    acc = np.diag(cm)/cm.sum(axis=1) # the per class accuracy is the diagonals (tp) divided by all cases of that class\n",
        "    return cm, acc, ave_loss\n",
        "\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDUfCiS6swD_"
      },
      "source": [
        "# Load the MNIST dataset\n",
        "transform_mnist = transforms.Compose( [transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,)) ] )\n",
        "trainset_mnist = torchvision.datasets.MNIST('./mnist', download=True, train=True, transform=transform_mnist)\n",
        "testset_mnist = torchvision.datasets.MNIST('./mnist', download=True, train=False, transform=transform_mnist)\n",
        "\n",
        "batch_size = 64\n",
        "train_dl_mnist = DataLoader(trainset_mnist, batch_size=batch_size, shuffle=True)\n",
        "test_dl_mnist = DataLoader(testset_mnist, batch_size=batch_size, shuffle=True)\n",
        "imgnet_mnist = ImgNet(28*28,128,64,10).cuda()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the NN on the MNIST data\n",
        "loss_fn_mnist = torch.nn.functional.nll_loss\n",
        "opt_mnist = torch.optim.SGD(imgnet_mnist.parameters(), lr=0.003, momentum=0.9) # where did I get these \"magic numbers?\"  Trial and error and voodoo.\n",
        "fit(15, imgnet_mnist, train_dl_mnist, loss_fn_mnist, opt_mnist)"
      ],
      "metadata": {
        "id": "IMn6yYYeeg6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PfN_n-ttKmT"
      },
      "source": [
        "# Show prediction for a random MNIST image\n",
        "images, labels = next(iter(test_dl_mnist))\n",
        "img = images[0].to(\"cuda\")\n",
        "label = labels[0].to(\"cuda\").item()\n",
        "\n",
        "with torch.no_grad():\n",
        "  predLabel = torch.argmax(imgnet_mnist(img.view(1,-1))).item()\n",
        "\n",
        "imshow(img)\n",
        "print(f\"Predicted label was: {predLabel} ; Actual label was: {label}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446fYlcnXzWA"
      },
      "source": [
        "# Evaluate performance of our NN on MNIST holdout data\n",
        "cm_mnist, acc_mnist, ave_loss_mnist = test(imgnet_mnist, test_dl_mnist, loss_fn_mnist)\n",
        "print(ave_loss_mnist)\n",
        "print(cm_mnist)\n",
        "print(acc_mnist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc: Load CIFAR and Train a simple NN model on it"
      ],
      "metadata": {
        "id": "kY6q-XnAeKEe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQFeLRidszwV"
      },
      "source": [
        "# Load the CIFAR10 data\n",
        "transform_cifar = transforms.Compose( [ transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) ] )\n",
        "trainset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform_cifar)\n",
        "testset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "batch_size = 64\n",
        "train_dl_cifar = DataLoader(trainset_cifar, batch_size=batch_size, shuffle=True)\n",
        "test_dl_cifar = DataLoader(testset_cifar, batch_size=batch_size, shuffle=True)\n",
        "imgnet_cifar = ImgNet(3*32*32,128,64,10).cuda()\n",
        "\n",
        "# Train the NN\n",
        "loss_fn_cifar = torch.nn.functional.nll_loss\n",
        "opt_cifar = torch.optim.SGD(imgnet_cifar.parameters(), lr=0.003, momentum=0.9) # where did I get these \"magic numbers?\"  Trial and error and voodoo.\n",
        "fit(15, imgnet_cifar, train_dl_cifar, loss_fn_cifar, opt_cifar)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJKMi40n1w3k"
      },
      "source": [
        "# Print an example\n",
        "images, labels = next(iter(test_dl_cifar))\n",
        "img = images[0].to(\"cuda\")\n",
        "label = labels[0].to(\"cuda\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  predLabel = torch.argmax(imgnet_cifar(img.view(1,-1))).item()\n",
        "\n",
        "imshow(img)\n",
        "print(f\"Predicted label was: {testset_cifar.classes[predLabel]} ; Actual label was: {testset_cifar.classes[label]}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc: Increasing Loss / Exploding Gradients"
      ],
      "metadata": {
        "id": "35gXwFWFKdbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a very simple example of a single neuron (linear layer) with no activation function -- i.e., this is just linear regression (using the wine quality data). \n",
        "\n",
        "Here's an example of where the loss function \"turns around\" during training.  This is an example of an \"exploding gradient\". I captured here the range of epochs where the loss \"turns around\" by carefully selecting the learning rate."
      ],
      "metadata": {
        "id": "86O065tzLMqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.info()"
      ],
      "metadata": {
        "id": "yeiHgCc7SNQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "\n",
        "wine_df = pd.read_csv('https://raw.githubusercontent.com/dylanwalker/MGSC496/main/datasets/winequality-red.csv')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(wine_df.loc[:,'fixed acidity':'alcohol'])\n",
        "wine_df.loc[:,'fixed acidity':'alcohol'] = scaler.transform(wine_df.loc[:,'fixed acidity':'alcohol'])\n",
        "wine_df.quality = wine_df.quality/10\n",
        "\n",
        "\n",
        "inputs = torch.tensor(wine_df.loc[:,'fixed acidity':'alcohol'].values, dtype=torch.float32)\n",
        "targets = torch.tensor(wine_df.loc[:,'quality'].values, dtype=torch.float32) \n",
        "\n",
        "full_ds = TensorDataset(inputs, targets)\n",
        "train_ds, test_ds = random_split(full_ds, [0.8, 0.2])\n",
        "\n",
        "batch_size = len(train_ds)\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "test_dl = DataLoader(test_ds, batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "def fit_gd(num_epochs, model, train_dl, test_dl, loss_fn, opt):\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    model.train() \n",
        "    for epoch in range(num_epochs):\n",
        "      loss_for_epoch = 0\n",
        "      vloss_for_epoch = 0\n",
        "      for xb,yb in train_dl: \n",
        "        pred = model(xb) \n",
        "        loss = loss_fn(pred, yb.view(-1,1)) \n",
        "        loss_for_epoch += loss.item() \n",
        "        loss.backward()\n",
        "      opt.step() \n",
        "      opt.zero_grad()\n",
        "      training_losses.append(loss_for_epoch)\n",
        "      # Calculate validation loss for each epoch\n",
        "      model.eval()\n",
        "      for xvb, yvb in test_dl:\n",
        "        with torch.no_grad():\n",
        "          predv = model(xvb)\n",
        "          vloss = loss_fn(predv, yvb.view(-1,1))\n",
        "          vloss_for_epoch += vloss.item()\n",
        "      validation_losses.append(vloss_for_epoch)\n",
        "      model.train()\n",
        "    return training_losses, validation_losses \n",
        "\n",
        "num_epochs_exploding = 100 \n",
        "lr_exploding = 3.229e-1\n",
        "lr_reasonable = 1e-5\n",
        "lr = lr_exploding\n",
        "num_epochs = num_epochs_exploding\n",
        "\n",
        "model = torch.nn.Linear(11,1) \n",
        "opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "loss_fn = torch.nn.functional.mse_loss\n",
        "\n",
        "\n",
        "\n",
        "training_losses, validation_losses = fit_gd(num_epochs, model, train_dl, test_dl, loss_fn, opt)"
      ],
      "metadata": {
        "id": "xkmaqD3qMLLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "losses_df = pd.DataFrame({'epoch':range(len(training_losses)),'training_loss':training_losses,'validation_loss':validation_losses})\n",
        "fig = px.line(losses_df,x='epoch',y=['training_loss','validation_loss'])\n",
        "fig.update_layout(yaxis_title='loss')"
      ],
      "metadata": {
        "id": "B_lrd-JvSQKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that the loss function is decreasing as we would expect, at first. But at some point it turns around. If we were to keep training, the gradient would eventually explode and go to \"infinity\" (past the point where we can keep track of the values, so it would become \"inf\" or \"NaN\").\n",
        "\n",
        "The primary culprit in this example is that our learning rate is too high. In other words, the steps we are taking to adjust the weights of our NN are just too big. This is one reason why you always need to look at the training loss.\n"
      ],
      "metadata": {
        "id": "Cj9tXDKgLo7u"
      }
    }
  ]
}