{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7ypdp3XeOf0bKrVlRrk8y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanwalker/MGSC496/blob/main/MGSC496_CountryScraper_extracting_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting data from Country Data on [this site](https://www.scrapethissite.com/pages/simple/)\n"
      ],
      "metadata": {
        "id": "unNsRz_6V0Lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To get started building a scraper for this site containing Country data, the first thing I do is install parsel and import the Selector class (so I can play with xpaths). \n",
        "\n",
        "Next, I use the `requests` library to get the source of the page, name it `doc` and then make a Selector object out of it using:\n",
        "\n",
        " ```python\n",
        " selector = Selector(doc)\n",
        " ```"
      ],
      "metadata": {
        "id": "OwI7KQyBbBcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install parsel"
      ],
      "metadata": {
        "id": "G-_gpUzvPY5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from parsel import Selector\n",
        "import requests\n",
        "res = requests.get('https://www.scrapethissite.com/pages/simple/')\n",
        "doc = res.text\n",
        "selector = Selector(doc)"
      ],
      "metadata": {
        "id": "OGn2UcvTcOPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once, I've done that I inspect various element of the page in my browser and figure out which pieces of data I want to extract, and then figure out an xpath for each one. I print out the variables as I go, so I can see what I'm extracting from this first page and keep adding variables that capture the data items until I get something that looks like this: "
      ],
      "metadata": {
        "id": "eNBcivRoWQQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countries = selector.xpath('//div[@class=\"row\"]/div[contains(@class,\"country\")]')\n",
        "for country in countries:\n",
        "  country_name = country.xpath('*[@class=\"country-name\"]/text()').getall()[1].strip()\n",
        "  capital = country.xpath('*[@class=\"country-info\"]/*[@class=\"country-capital\"]/text()').get()\n",
        "  population = country.xpath('*[@class=\"country-info\"]/*[@class=\"country-population\"]/text()').get()\n",
        "  area = country.xpath('*[@class=\"country-info\"]/*[@class=\"country-area\"]/text()').get()\n",
        "  print(f\"{country_name}, {capital}, {population}, {area}\")"
      ],
      "metadata": {
        "id": "635cnjtfcAIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I know how to get everything I want, I can make a new scraper and put all this data extraction code into the spider."
      ],
      "metadata": {
        "id": "eW0no3-rWnhH"
      }
    }
  ]
}