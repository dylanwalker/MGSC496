{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9R529DfMrsC8RnBE3bJS/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanwalker/MGSC496/blob/main/MGSC496_L09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the in-class notebook for MGSC496 Lecture 9."
      ],
      "metadata": {
        "id": "RT9odU7BzKCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "s7hNTaBJNEfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to mention:\n",
        "* ??"
      ],
      "metadata": {
        "id": "7Yt8xDXSyHVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Exercise Solution: Single Neuron to Predict Cat\n",
        " "
      ],
      "metadata": {
        "id": "Glj0D2qD8H_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dW5_8Wpj8OL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>\n",
        "<img src=\"https://drive.google.com/uc?id=1sk8CSP26YY7sfyzmHGFXncuNRujkvu9v\" align=\"left\">\n",
        "\n",
        "<font size=3 color=\"darkred\">Exercise:  Make a single-layer NN to predict whether an animal is a cat</font>\n",
        "\n",
        "Let's take some data on different animals and build our own single-layer neural network (one neuron) that predicts whether an animal is a cat based on some features. We haven't talked about how to **train** a neural network yet, so we'll just make our weights random and keep trying until we get something that gives the right prediction.\n",
        "\n",
        "Here is some data on different animals:"
      ],
      "metadata": {
        "id": "IpDtp1rvHdNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Qsh-jBDT5Wc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_df = pd.DataFrame({'is_mammal':[1,1,1,0],\n",
        "                       'four_legged':[0,1,1,1],\n",
        "                       'body_weight_lbs':[70.0,8800.0,9.0,0.5],\n",
        "                       'body_height_inches':[36.0,324.0,9.0,1.0],\n",
        "                       'has_thumbs':[1,0,0,0],\n",
        "                       'animal':['chimp','elephant','cat','lizard'],\n",
        "                       'is_cat':[0,0,1,0]})\n",
        "cat_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "D6Ft0nGD5YmD",
        "outputId": "84411be7-0bf2-468d-842c-9c35cc897219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   is_mammal  four_legged  body_weight_lbs  body_height_inches  has_thumbs  \\\n",
              "0          1            0             70.0                36.0           1   \n",
              "1          1            1           8800.0               324.0           0   \n",
              "2          1            1              9.0                 9.0           0   \n",
              "3          0            1              0.5                 1.0           0   \n",
              "\n",
              "     animal  is_cat  \n",
              "0     chimp       0  \n",
              "1  elephant       0  \n",
              "2       cat       1  \n",
              "3    lizard       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9a76d26-e534-4af5-80e0-2c837d7477d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_mammal</th>\n",
              "      <th>four_legged</th>\n",
              "      <th>body_weight_lbs</th>\n",
              "      <th>body_height_inches</th>\n",
              "      <th>has_thumbs</th>\n",
              "      <th>animal</th>\n",
              "      <th>is_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1</td>\n",
              "      <td>chimp</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8800.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>0</td>\n",
              "      <td>elephant</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>cat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>lizard</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9a76d26-e534-4af5-80e0-2c837d7477d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9a76d26-e534-4af5-80e0-2c837d7477d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9a76d26-e534-4af5-80e0-2c837d7477d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the first five columns as our features $x$. Our goal is to randomly pick five weights $w_i$ ($i=0,...,4$) and one bias $b$ and then calculate $y = \\delta(\\sum_i{w_i x_i} + b)$. \n",
        "\n",
        "If $x$ is a numpy array of all the features, then we can use `np.dot(x,w)` to do the summation term, $\\sum_i{w_i x_i}$ , we can add the bias $b$ to this and then use a version of the step function $\\delta()$:.\n",
        "\n",
        "```python\n",
        "yhat = delta(np.dot(x,w)+b)\n",
        "```\n",
        "\n",
        "Before we do this, however, we should think about the weights and the features. As we learned from studying sklearn, ML models often struggle when the numerical features of data are distributed very differently. Our data includes dummy variables (which are either 0 or 1) and some numerical variables (like `body_weight_lbs` and `body_height_inches`) which have very different scales. If we're going to pick some random values for the weights and biases, we'll have to us a function from the numpy module to give us those random numbers.\n",
        "\n",
        "But how should these weights be distributed? If all of our features had mean and standard deviation close to 1, then we could draw our weights and bias from a random normal distribution. Let's do that.\n",
        "\n",
        "In a single code block:\n",
        "\n",
        "1. Use the `StandardScaler` that you learned about from studying sklearn to standardize all of the features.\n",
        "\n",
        "2. Use `np.random.rand()` to generate 5 weights and 1 bias from the random normal distribution\n",
        "\n",
        "3. Use `yhat = delta(np.dot(x,w)+b)` (I've defined the delta function defined for you below) to get a prediction(`True` or `False` for whether each data point is a cat.\n",
        "\n",
        "4. Rerun your code and watch how different random choices of weights and bias lead to different answers\n"
      ],
      "metadata": {
        "id": "6EiCa99yISSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delta(x, thresh=0.5):\n",
        "  sigmoid = 1/(1+np.exp(-x))\n",
        "  return (sigmoid>thresh)"
      ],
      "metadata": {
        "id": "wxcqErdqXALE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Use the StandardScaler from sklearn. Fit this to the first 5 columns of cat_df and then use .transform() to transform the first 5 columns of the data (the features)\n",
        "#    and define this variable as x\n",
        "x = cat_df.loc[:,'is_mammal':'has_thumbs']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x)\n",
        "x = scaler.transform(x)\n",
        "\n",
        "# 2. Use np.random.randn() to generate a random numpy array of 5 normally distributed weights called w. Also use it to generate a random numpy array of 1 normally\n",
        "#    distibruted bias called b. Print out w and b\n",
        "w = np.random.randn(5)\n",
        "b = np.random.randn(1)\n",
        "print(w)\n",
        "print(b)\n",
        "\n",
        "# 3. Use yhat = delta(np.dot(x,w)+b) to get a prediction (for each row of the data) of whether the row is a cat and print out yhat\n",
        "yhat = delta(np.dot(x,w)+b)\n",
        "print(yhat)\n",
        "\n",
        "# Re-run this cell multiple times and look for the result [False False True False] -- this is predicting the cat is a cat and all others are not"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRuoAqZBHdN6",
        "outputId": "258948fa-0b86-434a-bb6a-8a587babdac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.96383719 -0.13417717 -0.71409171 -0.75798395  1.29879528]\n",
            "[-1.07256832]\n",
            "[ True False False  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have found a set of weights and bias that give the right prediction on the training data. Of course, we want a **training procedure** that intelligently updates the weights (rather than just pick them randomly) to minimize some error (or \"Loss Function\"). We also would want our neural network (here just a single neuron) to predict correctly on unseen data (test data). We will talk about this, but first let's talk about moving from a single neuron to a **neural network**."
      ],
      "metadata": {
        "id": "kBHAAdo1zTSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "zVeI-dkMHdN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Training a single neuron:"
      ],
      "metadata": {
        "id": "q9YHwhhon9WT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's repeat the above, but try to use our understanding of how a neural net is trained to update the weights/biases intelligently, instead of just picking some random numbers.\n",
        "\n",
        "Instead of setting the output to true or false, I'll keep the number after the sigmoid, as this will be better for training:"
      ],
      "metadata": {
        "id": "zkyZmMOHoD3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x, thresh=0.5):\n",
        "  sigmoid = 1/(1+torch.exp(-x))\n",
        "  return sigmoid"
      ],
      "metadata": {
        "id": "6Co6ydfDb__h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can just make some random weights with pytorch (you'll read about this soon, but for now, just know that pytorch keeps track of and calculates the gradients for us, which is something that numpy doesn't do!):"
      ],
      "metadata": {
        "id": "uK9OZlOZgXgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(np.random.randn(5),requires_grad=True) # make a random tensor of 5 weights.\n",
        "b = torch.tensor(np.random.randn(1),requires_grad=True) # make a random tensor of a single bias.\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HN99PLIcBLy",
        "outputId": "a288aa1e-c9b4-4178-c8f0-a03ecfad59c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0933, -0.3533, -1.1217,  0.8401, -2.1974], dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "tensor([-0.9246], dtype=torch.float64, requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the last reading/lecture we used `np.dot()` to multiple the features by the weights. More generally, to get a weighted sum of the input features, we will use matrix multiplication. The operator to do  matrix multiplication in numpy and pytorch is `@`. So, to get the weighted sum that we want to pass into our nonlinear function, where the $i$th element is:\n",
        "\n",
        "$\\hat{y}_i =  \\delta ( w_0X_{i0}+w_1X_{i1}+w_2X_{i2}+w_3X_{i3}+w_4X_{i4}+b )$\n",
        "\n",
        "we can us `X @ w` like this:"
      ],
      "metadata": {
        "id": "sc1i-fuCeJJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = delta(X @ w + b)\n",
        "yhat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaCCa0EecONY",
        "outputId": "51cb6457-4c9f-45fc-bcc6-ff00275c10d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0288, 0.2973, 0.5803, 0.4784], dtype=torch.float64,\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FInally we can make a cost function which takes all the predicted outcomes $\\hat{y}$ and all the actual outcomes $y$ and calculates a single scalar (in this case, the sum of the squared difference between each predicted outcome and each actual outcome):"
      ],
      "metadata": {
        "id": "CzMhfca2g4Mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = ((yhat - y)**2).sum() # Define the cost as the sum of the squared difference\n",
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HW0l5xhdQ5E",
        "outputId": "259fca4a-f1fb-4cdf-a317-319aab52ae1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4942, dtype=torch.float64, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, instead of randomly guessing weights and bias until we get a set that gives us the right prediction, we can use pytorch to get the gradient:"
      ],
      "metadata": {
        "id": "G2lAm-4TgOkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C.backward() # this call will tell pytorch to use backward propagation to produce gradients for w and b "
      ],
      "metadata": {
        "id": "Sm8LRF4XdmMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLmZLfKzeBhZ",
        "outputId": "b6c48a72-6b32-43b8-f3d9-a11907735963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4589,  0.0888,  0.1938,  0.1779, -0.0888], dtype=torch.float64)\n",
            "tensor([0.1602], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gradient values above are the relative amounts that we have to nudges each weight/bias. Typically, we multiply these nudges by a small number, called the learning rate. This is \"taking a tiny step in the right direction\".\n",
        "\n",
        "When we do this weight update in pytorch, we have to tell it that we are \"just updating the weights\" and its gradient package should not pay attention to  any calculation (we'll also talke about this later). We do this with `with torch.no_grad()`:"
      ],
      "metadata": {
        "id": "XNwocI9wh-9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # tell pytorch not to use the equations in this code block to setup autograd relationships\n",
        "  w-=w.grad*5e-2 # move w a bit in the right direction, learning rate is 0.05\n",
        "  b-=b.grad*5e-2 # move b a bit in the right direction, learning rate is 0.05\n",
        "  w.grad.zero_() # now set all the gradients to zero so we can feed the entire training data back through again next epoch\n",
        "  b.grad.zero_()\n"
      ],
      "metadata": {
        "id": "DPLAALafi8FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)\n",
        "yhat = delta(X @ w + b)\n",
        "yhat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebqcsrp6jOG2",
        "outputId": "5a207b09-c6ad-4427-dd30-13211fee8d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2062, -0.4249, -1.2659,  0.7071, -2.1258], dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "tensor([-1.0515], dtype=torch.float64, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0305, 0.2841, 0.5858, 0.4579], dtype=torch.float64,\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to train single neuron \"is_cat\" predictor\n",
        "\n",
        "w = torch.tensor(np.random.randn(5),requires_grad=True)\n",
        "b = torch.tensor(np.random.randn(1),requires_grad=True)\n",
        "\n",
        "for epoch in range(1,1000):\n",
        "  yhat = delta(X @ w + b)\n",
        "  C = ((yhat - y)**2).sum()\n",
        "  if epoch%100==0:\n",
        "    print(f\"yhat = {yhat}\")\n",
        "    print(f\"cost: {C}\")\n",
        "  C.backward()\n",
        "  with torch.no_grad():\n",
        "    w-=w.grad*5e-2\n",
        "    b-=b.grad*5e-2\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjFJyDIyk-WE",
        "outputId": "9eedc17e-cd70-43c6-9d7b-43daca746120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yhat = tensor([0.1364, 0.1257, 0.6720, 0.2269], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.19347783343739194\n",
            "yhat = tensor([0.1014, 0.1009, 0.8205, 0.1477], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.07450588159983429\n",
            "yhat = tensor([0.0825, 0.0827, 0.8664, 0.1145], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.044609512773799175\n",
            "yhat = tensor([0.0707, 0.0710, 0.8898, 0.0961], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.031414565887348395\n",
            "yhat = tensor([0.0626, 0.0629, 0.9044, 0.0841], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.024082368683748818\n",
            "yhat = tensor([0.0567, 0.0569, 0.9146, 0.0755], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.019450716072030402\n",
            "yhat = tensor([0.0521, 0.0523, 0.9222, 0.0691], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.01627412839514157\n",
            "yhat = tensor([0.0484, 0.0486, 0.9281, 0.0640], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.013966856901682435\n",
            "yhat = tensor([0.0454, 0.0456, 0.9329, 0.0598], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "cost: 0.012218584626200858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8lrCxzimbLU",
        "outputId": "70dd0fa3-e5f2-4314-80f8-e28bece30d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.4109,  1.1539, -1.6755, -0.8196, -1.2763], dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "tensor([-1.5820], dtype=torch.float64, requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}